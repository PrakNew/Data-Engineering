{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sources for MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Mllib- Machine Learning Models').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"pandas==0.25.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pandas to Spark DataFrames\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['price'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+\n",
      "|CRIM   |ZN  |INDUS|CHAS|NOX  |RM   |AGE  |DIS   |RAD|TAX  |PTRATIO|B     |LSTAT|price|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+\n",
      "|0.00632|18.0|2.31 |0.0 |0.538|6.575|65.2 |4.09  |1.0|296.0|15.3   |396.9 |4.98 |24.0 |\n",
      "|0.02731|0.0 |7.07 |0.0 |0.469|6.421|78.9 |4.9671|2.0|242.0|17.8   |396.9 |9.14 |21.6 |\n",
      "|0.02729|0.0 |7.07 |0.0 |0.469|7.185|61.1 |4.9671|2.0|242.0|17.8   |392.83|4.03 |34.7 |\n",
      "|0.03237|0.0 |2.18 |0.0 |0.458|6.998|45.8 |6.0622|3.0|222.0|18.7   |394.63|2.94 |33.4 |\n",
      "|0.06905|0.0 |2.18 |0.0 |0.458|7.147|54.2 |6.0622|3.0|222.0|18.7   |396.9 |5.33 |36.2 |\n",
      "|0.02985|0.0 |2.18 |0.0 |0.458|6.43 |58.7 |6.0622|3.0|222.0|18.7   |394.12|5.21 |28.7 |\n",
      "|0.08829|12.5|7.87 |0.0 |0.524|6.012|66.6 |5.5605|5.0|311.0|15.2   |395.6 |12.43|22.9 |\n",
      "|0.14455|12.5|7.87 |0.0 |0.524|6.172|96.1 |5.9505|5.0|311.0|15.2   |396.9 |19.15|27.1 |\n",
      "|0.21124|12.5|7.87 |0.0 |0.524|5.631|100.0|6.0821|5.0|311.0|15.2   |386.63|29.93|16.5 |\n",
      "|0.17004|12.5|7.87 |0.0 |0.524|6.004|85.9 |6.5921|5.0|311.0|15.2   |386.71|17.1 |18.9 |\n",
      "|0.22489|12.5|7.87 |0.0 |0.524|6.377|94.3 |6.3467|5.0|311.0|15.2   |392.52|20.45|15.0 |\n",
      "|0.11747|12.5|7.87 |0.0 |0.524|6.009|82.9 |6.2267|5.0|311.0|15.2   |396.9 |13.27|18.9 |\n",
      "|0.09378|12.5|7.87 |0.0 |0.524|5.889|39.0 |5.4509|5.0|311.0|15.2   |390.5 |15.71|21.7 |\n",
      "|0.62976|0.0 |8.14 |0.0 |0.538|5.949|61.8 |4.7075|4.0|307.0|21.0   |396.9 |8.26 |20.4 |\n",
      "|0.63796|0.0 |8.14 |0.0 |0.538|6.096|84.5 |4.4619|4.0|307.0|21.0   |380.02|10.26|18.2 |\n",
      "|0.62739|0.0 |8.14 |0.0 |0.538|5.834|56.5 |4.4986|4.0|307.0|21.0   |395.62|8.47 |19.9 |\n",
      "|1.05393|0.0 |8.14 |0.0 |0.538|5.935|29.3 |4.4986|4.0|307.0|21.0   |386.85|6.58 |23.1 |\n",
      "|0.7842 |0.0 |8.14 |0.0 |0.538|5.99 |81.7 |4.2579|4.0|307.0|21.0   |386.75|14.67|17.5 |\n",
      "|0.80271|0.0 |8.14 |0.0 |0.538|5.456|36.6 |3.7965|4.0|307.0|21.0   |288.99|11.69|20.2 |\n",
      "|0.7258 |0.0 |8.14 |0.0 |0.538|5.727|69.5 |3.7965|4.0|307.0|21.0   |390.95|11.28|18.2 |\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(df)\n",
    "sdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[c for c in sdf.columns if c != 'price'],\n",
    "                            outputCol='features')\n",
    "dataset = assembler.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|  TAX|PTRATIO|     B|LSTAT|price|            features|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "|0.00632|18.0| 2.31| 0.0|0.538|6.575| 65.2|  4.09|1.0|296.0|   15.3| 396.9| 4.98| 24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07| 0.0|0.469|6.421| 78.9|4.9671|2.0|242.0|   17.8| 396.9| 9.14| 21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07| 0.0|0.469|7.185| 61.1|4.9671|2.0|242.0|   17.8|392.83| 4.03| 34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18| 0.0|0.458|6.998| 45.8|6.0622|3.0|222.0|   18.7|394.63| 2.94| 33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18| 0.0|0.458|7.147| 54.2|6.0622|3.0|222.0|   18.7| 396.9| 5.33| 36.2|[0.06905,0.0,2.18...|\n",
      "|0.02985| 0.0| 2.18| 0.0|0.458| 6.43| 58.7|6.0622|3.0|222.0|   18.7|394.12| 5.21| 28.7|[0.02985,0.0,2.18...|\n",
      "|0.08829|12.5| 7.87| 0.0|0.524|6.012| 66.6|5.5605|5.0|311.0|   15.2| 395.6|12.43| 22.9|[0.08829,12.5,7.8...|\n",
      "|0.14455|12.5| 7.87| 0.0|0.524|6.172| 96.1|5.9505|5.0|311.0|   15.2| 396.9|19.15| 27.1|[0.14455,12.5,7.8...|\n",
      "|0.21124|12.5| 7.87| 0.0|0.524|5.631|100.0|6.0821|5.0|311.0|   15.2|386.63|29.93| 16.5|[0.21124,12.5,7.8...|\n",
      "|0.17004|12.5| 7.87| 0.0|0.524|6.004| 85.9|6.5921|5.0|311.0|   15.2|386.71| 17.1| 18.9|[0.17004,12.5,7.8...|\n",
      "|0.22489|12.5| 7.87| 0.0|0.524|6.377| 94.3|6.3467|5.0|311.0|   15.2|392.52|20.45| 15.0|[0.22489,12.5,7.8...|\n",
      "|0.11747|12.5| 7.87| 0.0|0.524|6.009| 82.9|6.2267|5.0|311.0|   15.2| 396.9|13.27| 18.9|[0.11747,12.5,7.8...|\n",
      "|0.09378|12.5| 7.87| 0.0|0.524|5.889| 39.0|5.4509|5.0|311.0|   15.2| 390.5|15.71| 21.7|[0.09378,12.5,7.8...|\n",
      "|0.62976| 0.0| 8.14| 0.0|0.538|5.949| 61.8|4.7075|4.0|307.0|   21.0| 396.9| 8.26| 20.4|[0.62976,0.0,8.14...|\n",
      "|0.63796| 0.0| 8.14| 0.0|0.538|6.096| 84.5|4.4619|4.0|307.0|   21.0|380.02|10.26| 18.2|[0.63796,0.0,8.14...|\n",
      "|0.62739| 0.0| 8.14| 0.0|0.538|5.834| 56.5|4.4986|4.0|307.0|   21.0|395.62| 8.47| 19.9|[0.62739,0.0,8.14...|\n",
      "|1.05393| 0.0| 8.14| 0.0|0.538|5.935| 29.3|4.4986|4.0|307.0|   21.0|386.85| 6.58| 23.1|[1.05393,0.0,8.14...|\n",
      "| 0.7842| 0.0| 8.14| 0.0|0.538| 5.99| 81.7|4.2579|4.0|307.0|   21.0|386.75|14.67| 17.5|[0.7842,0.0,8.14,...|\n",
      "|0.80271| 0.0| 8.14| 0.0|0.538|5.456| 36.6|3.7965|4.0|307.0|   21.0|288.99|11.69| 20.2|[0.80271,0.0,8.14...|\n",
      "| 0.7258| 0.0| 8.14| 0.0|0.538|5.727| 69.5|3.7965|4.0|307.0|   21.0|390.95|11.28| 18.2|[0.7258,0.0,8.14,...|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='price')\n",
    "model = lr.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406426641094093\n"
     ]
    }
   ],
   "source": [
    "summary = model.evaluate(dataset)\n",
    "print(summary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithms may have different interfaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "| 26.11515151515151|\n",
      "| 21.04507042253521|\n",
      "|34.864705882352936|\n",
      "|34.864705882352936|\n",
      "|34.864705882352936|\n",
      "|24.206976744186047|\n",
      "| 21.04507042253521|\n",
      "|19.549999999999997|\n",
      "| 16.20724637681159|\n",
      "|19.549999999999997|\n",
      "| 16.20724637681159|\n",
      "| 21.04507042253521|\n",
      "|21.981818181818184|\n",
      "| 21.04507042253521|\n",
      "| 21.04507042253521|\n",
      "| 21.04507042253521|\n",
      "|24.206976744186047|\n",
      "| 16.20724637681159|\n",
      "| 21.04507042253521|\n",
      "| 21.04507042253521|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model.transform(dataset)\n",
    "output.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|price|\n",
      "+-----+\n",
      "| 24.0|\n",
      "| 21.6|\n",
      "| 34.7|\n",
      "| 33.4|\n",
      "| 36.2|\n",
      "| 28.7|\n",
      "| 22.9|\n",
      "| 27.1|\n",
      "| 16.5|\n",
      "| 18.9|\n",
      "| 15.0|\n",
      "| 18.9|\n",
      "| 21.7|\n",
      "| 20.4|\n",
      "| 18.2|\n",
      "| 19.9|\n",
      "| 23.1|\n",
      "| 17.5|\n",
      "| 20.2|\n",
      "| 18.2|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('price').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we evaluate this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098424850624001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol='price', predictionCol='prediction', metricName='r2')\n",
    "evaluator.evaluate(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_widthCm: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure that you replace the s3 path for the datase below.\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .option(\"header\", True)\\\n",
    "    .load(\"s3a://bucket-name/iris.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-------------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_widthCm|    species|\n",
      "+------------+-----------+------------+-------------+-----------+\n",
      "|         5.1|        3.5|         1.4|          0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|          0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|          0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|          0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|          0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[c for c in df.columns if c != 'species'],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='species')\n",
    "model = lr.fit(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_widthCm|        species|speciesIndex|\n",
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "|         5.1|        3.7|         1.5|          0.4|    Iris-setosa|         0.0|\n",
      "|         5.1|        3.3|         1.7|          0.5|    Iris-setosa|         0.0|\n",
      "|         5.0|        3.5|         1.3|          0.3|    Iris-setosa|         0.0|\n",
      "|         4.6|        3.2|         1.4|          0.2|    Iris-setosa|         0.0|\n",
      "|         5.7|        2.8|         4.1|          1.3|Iris-versicolor|         1.0|\n",
      "|         5.6|        2.8|         4.9|          2.0| Iris-virginica|         2.0|\n",
      "|         7.7|        3.0|         6.1|          2.3| Iris-virginica|         2.0|\n",
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='species', outputCol='speciesIndex')\n",
    "\n",
    "iris = indexer.fit(df).transform(df)\n",
    "\n",
    "iris.sample(fraction=0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[c for c in df.columns if not c.startswith('species')],\n",
    "                            outputCol='features')\n",
    "dataset = assembler.transform(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_widthCm: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      " |-- speciesIndex: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='speciesIndex')\n",
    "model = lr.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's too convenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = dataset.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(trainData)\n",
    "summary = model.evaluate(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Use the NaiveBayes classifier on the Iris dataset\n",
    "### Check the accuracy for a 60-40 train / test split.\n",
    "### Hint: Use the `MulticlassClassificationEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
